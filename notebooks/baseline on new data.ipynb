{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.read_csv(\"../data/new_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_train.copy()\n",
    "train = train.iloc[:10000].melt(id_vars=\"Page\", value_vars=list(train.columns[1:]), var_name=\"Date\", value_name=\"Visits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Visits\"].fillna(0, inplace=True)\n",
    "train[\"Visits\"] = train[\"Visits\"].astype(int)\n",
    "train[\"Date\"] = train[\"Date\"].astype('datetime64[ns]')\n",
    "train['Year'] = train[\"Date\"].dt.year\n",
    "train['Month'] = train[\"Date\"].dt.month\n",
    "train['Day'] = train[\"Date\"].dt.day\n",
    "train['DayOfWeek'] = train[\"Date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features_last_year(df):\n",
    "    for year in [1]:\n",
    "        for month in [0]:\n",
    "            for day in [-1, 0, 1]:\n",
    "                temp = df.copy()\n",
    "                temp[\"Date\"] = temp[\"Date\"].apply(lambda x: x + relativedelta(years=year, months=month, days=day))\n",
    "                temp.rename(columns={\"Visits\": \"prev_Visits_{}_{}_{}\".format(year, month, day)}, inplace=True)\n",
    "                df = df.merge(temp[[\"Page\", \"Date\", \"prev_Visits_{}_{}_{}\".format(year, month, day)]], on=[\"Page\", \"Date\"], how='left')\n",
    "                df[\"prev_Visits_{}_{}_{}\".format(year, month, day)] = df[\"prev_Visits_{}_{}_{}\".format(year, month, day)].fillna(0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_features_last_year(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation(df, default_month):\n",
    "    return df.loc[(df[\"Date\"] <= pd.to_datetime(default_month) - relativedelta(months=1)) & \\\n",
    "                  (df[\"Date\"] >= pd.to_datetime(default_month) - relativedelta(months=3))].index, \\\n",
    "           df.loc[(df[\"Date\"] >= pd.to_datetime(default_month)) & \\\n",
    "                  (df[\"Date\"] <= pd.to_datetime(default_month) + relativedelta(months=2))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2016-08-10 – 2016-10-10     Validation: 2016-11-10 – 2017-01-10\n",
      "Train: 2016-09-10 – 2016-11-10     Validation: 2016-12-10 – 2017-02-10\n",
      "Train: 2016-10-10 – 2016-12-10     Validation: 2017-01-10 – 2017-03-10\n",
      "Train: 2016-11-10 – 2017-01-10     Validation: 2017-02-10 – 2017-04-10\n",
      "Train: 2016-12-10 – 2017-02-10     Validation: 2017-03-10 – 2017-05-10\n"
     ]
    }
   ],
   "source": [
    "validation_months = ['2016-11-10', '2016-12-10', '2017-01-10', '2017-02-10', '2017-03-10']\n",
    "validation = []\n",
    "for month in validation_months:\n",
    "    validation.append(create_validation(train, month))\n",
    "    print(\"Train:\", str(train.loc[validation[-1][0], \"Date\"].min())[:10], \"–\", str(train.loc[validation[-1][0], \"Date\"].max())[:10],\n",
    "          \"    Validation:\", str(train.loc[validation[-1][1], \"Date\"].min())[:10], \"–\", str(train.loc[validation[-1][1], \"Date\"].max())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "param = {}\n",
    "param['application'] = 'regression_l2'\n",
    "param['learning_rate'] = 0.1\n",
    "param['feature_fraction'] = 0.5\n",
    "param['bagging_fraction'] = 0.5\n",
    "param['bagging_freq'] = 1\n",
    "param['max_depth'] = 5\n",
    "param['num_threads'] = 4\n",
    "param[\"verbose\"] = 0\n",
    "\n",
    "from numba import jit\n",
    "import math\n",
    "\n",
    "@jit\n",
    "def smape_fast(y_true, y_pred):\n",
    "    out = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        a = y_true[i]\n",
    "        b = y_pred[i]\n",
    "        if b < 1:\n",
    "            b = 0\n",
    "        c = a+b\n",
    "        if c == 0:\n",
    "            continue\n",
    "        out += math.fabs(a - b) / c\n",
    "    out *= (200.0 / y_true.shape[0])\n",
    "    return out\n",
    "\n",
    "def lgb_smape(preds, df):\n",
    "    labels = df.get_label()\n",
    "    labels, preds = np.expm1(np.array(labels)), np.expm1(np.array(preds))\n",
    "    return 'smape', smape_fast(labels, preds), False\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.mean(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lag_features(df, target, indexes, lags):\n",
    "    temp = pd.pivot_table(df.loc[(df[\"Date\"] > df.loc[indexes, \"Date\"].min() - relativedelta(days=8+lags))&\n",
    "                                 (df[\"Date\"] < df.loc[indexes, \"Date\"].min() - relativedelta(days=8))], \n",
    "                          index=[\"Page\"], values=[\"Visits\"], columns=[\"Date\"]).reset_index()\n",
    "    temp.columns = [\"lag_{}\".format(i)  if j[1] != \"\" else j[0] for i, j in enumerate(temp.columns)]\n",
    "    target = target.merge(temp, how='left')\n",
    "    return target\n",
    "\n",
    "def create_agg_features(df, indexes, lags, columns, name):\n",
    "    temp = df.loc[(df[\"Date\"] > df.loc[indexes, \"Date\"].min() - relativedelta(months=2, days=8+lags))&\n",
    "                  (df[\"Date\"] < df.loc[indexes, \"Date\"].min() - relativedelta(days=8))].groupby(columns)[\"Visits\"].agg([\"median\", \"mean\", \"std\", \"min\", \"max\"]).reset_index()\n",
    "    temp.columns = columns + [col + name + str(lags) for col in [\"median\", \"mean\", \"std\", \"min\", \"max\"]]\n",
    "    return temp\n",
    "\n",
    "def creating_features(df, indexes):\n",
    "    temp = df.loc[indexes].merge(create_agg_features(df, indexes, 10, [\"Page\", \"DayOfWeek\"], \"_p_d_\"), how='left', on=[\"Page\", \"DayOfWeek\"])\n",
    "    temp = temp.merge(create_agg_features(train, indexes, 10, [\"Page\"], \"_p_\"), how='left', on=[\"Page\"])\n",
    "    # create lag features\n",
    "    temp = create_lag_features(train, temp, indexes, 20)\n",
    "    # months from 0 to 2\n",
    "    for i, j in enumerate(temp[\"Month\"].unique()):\n",
    "        temp[\"Month\"].replace(j, i, inplace=True)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"train\": [], \"val\": [], \"iteration\": [], \"baseline\": []}\n",
    "for small_train, small_val in validation:\n",
    "    # TRAIN & VAL\n",
    "    # create aggregated features\n",
    "    fold_train = creating_features(train, small_train)\n",
    "    fold_val = creating_features(train, small_val)\n",
    "    \n",
    "    # apply log to all numeric features\n",
    "    numeric_features = [\"Visits\"] + list(fold_train.columns[7:])\n",
    "    fold_train[numeric_features] = np.log1p(fold_train[numeric_features])\n",
    "    fold_val[numeric_features] = np.log1p(fold_val[numeric_features])\n",
    "    \n",
    "    # preparing data from model\n",
    "    train_features = list(fold_train.columns[4:])\n",
    "    lgb_train = lgb.Dataset(fold_train[train_features], label=fold_train[\"Visits\"], free_raw_data=False)\n",
    "    lgb_val = lgb.Dataset(fold_val[train_features], label=fold_val[\"Visits\"], free_raw_data=False, reference=lgb_train)\n",
    "    \n",
    "    # model train\n",
    "    model = lgb.train(param, lgb_train, 1000, valid_sets=[lgb_train, lgb_val], feval=lgb_smape, early_stopping_rounds=10, verbose_eval=0)\n",
    "    \n",
    "    #save results\n",
    "    results['train'].append(model.best_score['training']['smape'])\n",
    "    results['val'].append(model.best_score['valid_1']['smape'])\n",
    "    results['iteration'].append(int(model.best_iteration))\n",
    "    results[\"baseline\"].append(smape(np.expm1(fold_val[\"Visits\"]), np.expm1(fold_val[\"median_p_d_10\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>iteration</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.772513</td>\n",
       "      <td>57</td>\n",
       "      <td>44.398178</td>\n",
       "      <td>44.325226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.787980</td>\n",
       "      <td>31</td>\n",
       "      <td>47.555058</td>\n",
       "      <td>45.232226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.599118</td>\n",
       "      <td>57</td>\n",
       "      <td>43.749827</td>\n",
       "      <td>46.219440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.304028</td>\n",
       "      <td>28</td>\n",
       "      <td>44.628191</td>\n",
       "      <td>41.332748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.378803</td>\n",
       "      <td>39</td>\n",
       "      <td>42.364963</td>\n",
       "      <td>39.876395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    baseline  iteration      train        val\n",
       "0  46.772513         57  44.398178  44.325226\n",
       "1  46.787980         31  47.555058  45.232226\n",
       "2  44.599118         57  43.749827  46.219440\n",
       "3  43.304028         28  44.628191  41.332748\n",
       "4  41.378803         39  42.364963  39.876395"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
